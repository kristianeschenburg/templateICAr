help(BioQC::entropy)
help(entropy)
BioQC::entropy(vector = hist_ii[,1])
entropy::entropy(hist_ii[,1])
log(sqrt(2*pi*exp()))
log(sqrt(2*pi*exp(1)))
#set.seed(10000)
t = 5000
phi = c(0, 0.1, 0.3, 0.5, 0.7)
M = 200
powers <- seq(0,t-1) #powers to raise phi to for covariance matrix
breaks <- seq(-10, 10, 0.001) #breaks for all the histograms
phi_ii <- phi[ii]
cov_mat <- toeplitz(phi_ii^powers)
dat_ii <- mvrnorm(n = M, mu = rep(0, t), Sigma = cov_mat)
#set.seed(10000)
t = 1000
phi = c(0, 0.1, 0.3, 0.5, 0.7)
dim(dat_ii)
head(dat_ii[,1:5])
head(dat_ii[,495:500])
tail(dat_ii[,495:500])
hist_ii1 <- hist(dat_ii[,1], breaks=breaks, plot=FALSE)
hist_ii1 <- hist_ii1$counts
length(hist_ii1)
entropy::entropy(hist_ii1)
BioQC::entropy(hist_ii1)
t
phi_ii <- phi[ii]
cov_mat <- toeplitz(phi_ii^powers)
system.time(dat_ii_dep <- mvrnorm(n = M, mu = rep(0, t), Sigma = cov_mat))
dim(cov_mat)
powers <- seq(0,t-1) #powers to raise phi to for covariance matrix
cov_mat <- toeplitz(phi_ii^powers)
system.time(dat_ii_dep <- mvrnorm(n = M, mu = rep(0, t), Sigma = cov_mat))
dat_ii_indep <- matrix(rnorm(n = t*M), nrow=t, ncol=M)
hist_ii2 <- hist(dat_ii[,2], breaks=breaks, plot=FALSE)
hist_ii <- cbind(hist_ii1, hist_ii2)
length(hist_ii1)
length(hist_ii2)
dim(dat_ii)
head(breaks)
hist_ii2 <- hist_ii2$counts
hist_ii <- cbind(hist_ii1, hist_ii2)
entropy(hist_ii[,1])
entropy(hist_ii[,2])
help(bioQC)
entropyDiversity(hist_ii)
entropy_sample <- function(x, breaks){
hist_x <- hist(x, breaks=breaks, plot=FALSE)
return(entropy::entropy(hist_x$counts))
}
entropy_dist_indep <- matrix(NA, nrow=M, ncol=length(phi))
entropy_dist_dep <- matrix(NA, nrow=M, ncol=length(phi))
powers <- seq(0,t-1) #powers to raise phi to for covariance matrix
breaks <- seq(-10, 10, 0.001) #breaks for all the histograms
entropy_dist_indep <- matrix(NA, nrow=M, ncol=length(phi))
entropy_dist_dep <- matrix(NA, nrow=M, ncol=length(phi))
for(ii in 1:length(phi)){
phi_ii <- phi[ii]
cov_mat <- toeplitz(phi_ii^powers)
dat_ii_indep <- matrix(rnorm(n = t*M), nrow=t, ncol=M)
dat_ii_dep <- mvrnorm(n = M, mu = rep(0, t), Sigma = cov_mat)
entropy_ii_indep <- apply(dat_ii_indep, 2, entropy_sample)
entropy_ii_dep <- apply(dat_ii_dep, 2, entropy_sample)
entropy_dist_indep[,ii] <- entropy_ii_indep
entropy_dist_dep[,ii] <- entropy_ii_dep
}
breaks <- seq(-10, 10, 0.001) #breaks for all the histograms
powers <- seq(0,t-1) #powers to raise phi to for covariance matrix
breaks <- seq(-10, 10, 0.001) #breaks for all the histograms
entropy_dist_indep <- matrix(NA, nrow=M, ncol=length(phi))
entropy_dist_dep <- matrix(NA, nrow=M, ncol=length(phi))
for(ii in 1:length(phi)){
print(ii)
phi_ii <- phi[ii]
cov_mat <- toeplitz(phi_ii^powers)
dat_ii_indep <- matrix(rnorm(n = t*M), nrow=t, ncol=M)
dat_ii_dep <- mvrnorm(n = M, mu = rep(0, t), Sigma = cov_mat)
entropy_ii_indep <- apply(dat_ii_indep, 2, entropy_sample, breaks=breaks)
entropy_ii_dep <- apply(dat_ii_dep, 2, entropy_sample, breaks=breaks)
entropy_dist_indep[,ii] <- entropy_ii_indep
entropy_dist_dep[,ii] <- entropy_ii_dep
}
length(entropy_ii_dep)
M
dim(dat_ii_dep)
t
library(knitr)
install_github('mandymejia/BayesfMRI')
library(devtools)
install_github('mandymejia/BayesfMRI')
library(roxygen2)
roxygenize()
library(templateICAr)
roxygenize()
roxygenize()
library(templateICAr)
roxygenize()
roxygenize()
library(templateICAr)
roxygenize()
library(templateICAr)
roxygenize()
library(templateICAr)
roxygenize()
library(templateICAr)
library(ggplot2)
#true values for unknown model parameters (we would not ever know these in real data)
beta0 <- 3
beta1 <- 12
sigma <- 20
sigma_sq <- sigma^2
n <- 64
n <- 64
set.seed(23467)
x <- runif(n, 0, 12)
xbar <- mean(x)
sdx <- sd(x)
niter <- 100
qplot() + xlim(0,12) + ylim(0,200) +
geom_abline(intercept=beta0, slope=beta1, col='black') +
theme_bw()
k=1
residuals_k <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
y_k <- beta0 + beta1*x + residuals_k
myplot <- qplot() + xlim(0,12) + ylim(0,200) +
geom_abline(intercept=beta0, slope=beta1, col='black') +
theme_bw()
print(k)
residuals_k <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
y_k <- beta0 + beta1*x + residuals_k
ybar_k <- mean(y_k)
sdy_k <- sd(y_k)
corxy_k <- cor(x, y_k)
beta1_hat_k <- corxy_k * sdy_k / sdx
beta0_hat_k <- ybar_k - beta1_hat_k*xbar
y_fitted_k <- beta0_hat_k + beta1_hat_k*x
residuals_fitted_k <- y_k - y_fitted_k
sigma_sq_hat_k <- 1/(n-2)*sum(residuals_fitted_k^2)
runif(5, 0, 12)
runif(5, 0, 12)
runif(5, 0, 12)
runif(5, 0, 12)
set.seed(23467)
runif(5, 0, 12)
set.seed(23467)
runif(5, 0, 12)
runif(5, 0, 12)
set.seed(1754843785413)
set.seed(784387)
runif(5, 0, 12)
set.seed(784387)
runif(5, 0, 12)
myplot <- myplot +
geom_point(data=NULL, aes(x=x, y=y_k)) +
geom_abline(intercept=beta0_hat_k, slope=beta1_hat_k, col='red', alpha=0.3)
myplot
myplot <- qplot() + xlim(0,12) + ylim(0,200) +
geom_abline(intercept=beta0, slope=beta1, col='black') +
theme_bw()
beta0_estimates <- rep(NA, niter)
beta1_estimates <- rep(NA, niter)
sigma_sq_estimates <- rep(NA, niter)
for(k in 1:niter){
print(k)
residuals_k <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
y_k <- beta0 + beta1*x + residuals_k
ybar_k <- mean(y_k)
sdy_k <- sd(y_k)
corxy_k <- cor(x, y_k)
beta1_hat_k <- corxy_k * sdy_k / sdx
beta0_hat_k <- ybar_k - beta1_hat_k*xbar
y_fitted_k <- beta0_hat_k + beta1_hat_k*x
residuals_fitted_k <- y_k - y_fitted_k
#qplot(residuals_k, residuals_fitted_k) #fitted residuals not equal to true residuals
sigma_sq_hat_k <- 1/(n-2)*sum(residuals_fitted_k^2)
if(k==1){
myplot <- myplot +
geom_point(data=NULL, aes(x=x, y=y_k)) +
geom_abline(intercept=beta0_hat_k, slope=beta1_hat_k, col='red', alpha=0.3)
} else{
myplot <- myplot +
geom_abline(intercept=beta0_hat_k, slope=beta1_hat_k, col='red', alpha=0.3)
}
beta0_estimates[k] <- beta0_hat_k
beta1_estimates[k] <- beta1_hat_k
sigma_sq_estimates[k] <- sigma_sq_hat_k
}
print(myplot)
hist(beta0_estimates)
hist(beta0_estimates, breaks=30)
abline(v=beta0, col='red')
hist(beta1_estimates, breaks=30)
abline(v=beta1, col='red')
hist(sigma_sq_estimates, breaks=30)
abline(v=sigma_sq, col='red')
library(INLA)
inla
for_pr_zy <- c(-65,512.5,  -69,237 )
for_pr_zy <- c(-65512.5,  -69237 )
for_pr_zy
pr_zy_inv_g <- sum(exp(for_pr_zy-for_pr_zy[g]))
g=1
pr_zy_inv_g <- sum(exp(for_pr_zy-for_pr_zy[g]))
1/pr_zy_inv_g
exp(-65512.5)
g=2
pr_zy_inv_g <- sum(exp(for_pr_zy-for_pr_zy[g]))
1/pr_zy_inv_g
exp(for_pr_zy-for_pr_zy[g])
for_pr_zy
(for_pr_zy-for_pr_zy[g])
exp(1000)
exp(100)
pr_zy_ing_g <- exp(c(100, 0))
1/pr_zy_ing_g
exp(50)
exp(20)
pr_zy_ing_g <- exp(c(20, 0))
pr_zy_inv_g <- sum(exp(exp(20,0)))
pr_zy_inv_g <- sum(exp(c(20,0)))
1/pr_zy_ing_g
pr_zy_inv_g <- sum(exp(c(10,0)))
1/pr_zy_ing_g
pr_zy_inv_g <- sum(exp(c(5,0)))
1/pr_zy_ing_g
pr_zy_inv_g <- sum(exp(c(20,0)))
1/pr_zy_inv_g
pr_zy_inv_g <- sum(exp(c(10,0)))
1/pr_zy_inv_g
pr_zy_inv_g <- sum(exp(c(5,0)))
1/pr_zy_inv_g
pr_zy_inv_g <- sum(exp(c(0,-5)))
1/pr_zy_inv_g
#install.packages('alr4')
library(alr4)
head(Highway)
install.packages('alr4')
#install.packages('alr4')
library(alr4)
head(Highway)
#Response Var: Accident Rate
#Potential Predictor Vars: Pct Truck Volume, Num Access points, Speed Limit, Shoulder Width
Highway2 <- Highway[,c('rate','trks','acpt','slim','shld')]
scatterplotMatrix(Highway2)
#Model 1: AccidentRate ~ Trucks + Speed Limit
lm1 <- lm(rate ~ trks + slim, data=Highway2)
summary(lm1)
#Model 1: AccidentRate ~ Speed Limit + Shoulder Width
lm1 <- lm(rate ~ slim + shld, data=Highway2)
summary(lm1)
#Added variable plot
m1a <- lm(rate ~ slim + shld, data=Highway2)
m1b <- lm(trks ~ slim + shld, data=Highway2)
resid1a <- residuals(m1a)
resid1b <- residuals(m1b)
library(ggthemes)
y_adj <- residuals(m1a)
x_adj <- residuals(m1b)
qplot(x=x_adj, y=y_adj) + geom_smooth() + theme_few()
library(ggplot2)
qplot(x=x_adj, y=y_adj) + geom_smooth() + theme_few()
lm2 <- lm(rate ~ slim + shld + trks, data=Highway2)
summary(lm2)
qplot(x=x_adj, y=y_adj) +
geom_smooth() + theme_few() +
xlab('Truck Volume, Adjusted for Speed Limit and Shoulder Width') +
ylab('Accident Rate, Adjusted for Speed Limit and Shoulder Width')
qplot(x=x_adj, y=y_adj) +
geom_smooth() + theme_few() +
ggtitle('Added Variable Plot, Adjusted for Speed Limit and Shoulder Width')
qplot(x=x_adj, y=y_adj) +
geom_smooth() + theme_few() +
ggtitle('Added Variable Plot, Adjusted for Speed Limit and Shoulder Width') +
xlab('Truck Volume (Adjusted)') +
ylab('Accident Rate (Adjusted)')
#Model 2: AccidentRate ~ Speed Limit + Shoulder Width + Truck Volume
lm2 <- lm(rate ~ slim + shld + trks, data=Highway2)
summary(lm2)
#Added variable plot
m2a <- lm(rate ~ slim + shld + trks, data=Highway2)
m2b <- lm(acpt ~ slim + shld + trks, data=Highway2)
y_adj <- residuals(m2a)
x_adj <- residuals(m2b)
qplot(x=x_adj, y=y_adj) +
geom_smooth() + theme_few() +
ggtitle('Added Variable Plot, Adjusted for Speed Limit, Shoulder Width & Truck Vol') +
xlab('Access Points (Adjusted)') +
ylab('Accident Rate (Adjusted)')
#Model 3: AccidentRate ~ Speed Limit + Shoulder Width + Truck Volume + Access Points
lm3 <- lm(rate ~ slim + shld + trks + acpt, data=Highway2)
summary(lm3)
library(ggplot2)
library(ggthemes)
#install.packages('alr4')
library(alr4)
#Response Var: Accident Rate
#Potential Predictor Vars: Pct Truck Volume, Num Access points, Speed Limit, Shoulder Width
Highway2 <- Highway[,c('rate','trks','acpt','slim','shld')]
scatterplotMatrix(Highway2)
#Model 1: AccidentRate ~ Speed Limit + Shoulder Width
lm1 <- lm(rate ~ slim + shld, data=Highway2)
summary(lm1)
qplot(x=x_adj, y=y_adj) +
geom_smooth() + theme_few() +
ggtitle('Added Variable Plot, Adjusted for Speed Limit and Shoulder Width') +
xlab('Truck Volume (Adjusted)') +
ylab('Accident Rate (Adjusted)')
#Added variable plot
m1a <- lm(rate ~ slim + shld, data=Highway2)
m1b <- lm(trks ~ slim + shld, data=Highway2)
y_adj <- residuals(m1a)
x_adj <- residuals(m1b)
qplot(x=x_adj, y=y_adj) +
geom_smooth() + theme_few() +
ggtitle('Added Variable Plot, Adjusted for Speed Limit and Shoulder Width') +
xlab('Truck Volume (Adjusted)') +
ylab('Accident Rate (Adjusted)')
ggplot(data=Highway2, aes(x=trks, y=rate)) +
geom_smooth() + theme_few() +
ggtitle('Accident Rate vs Truck Volume') +
xlab('Truck Volume') +
ylab('Accident Rate')
ggplot(data=Highway2, aes(x=trks, y=rate)) + geom_point() +
geom_smooth() + theme_few() +
ggtitle('Accident Rate vs Truck Volume') +
xlab('Truck Volume') +
ylab('Accident Rate')
#Model 2: AccidentRate ~ Speed Limit + Shoulder Width + Truck Volume
lm2 <- lm(rate ~ slim + shld + trks, data=Highway2)
summary(lm2)
m2a <- lm(rate ~ slim + shld + trks, data=Highway2)
m2b <- lm(acpt ~ slim + shld + trks, data=Highway2)
y_adj <- residuals(m2a)
x_adj <- residuals(m2b)
qplot(x=x_adj, y=y_adj) +
geom_smooth() + theme_few() +
ggtitle('Added Variable Plot, Adjusted for Speed Limit, Shoulder Width & Truck Vol') +
xlab('Access Points (Adjusted)') +
ylab('Accident Rate (Adjusted)')
ggplot(data=Highway2, aes(x=acpt, y=rate)) + geom_point() +
geom_smooth() + theme_few() +
ggtitle('Accident Rate vs Access Points') +
xlab('Access Points') +
ylab('Accident Rate')
#Model 3: AccidentRate ~ Speed Limit + Shoulder Width + Truck Volume + Access Points
lm3 <- lm(rate ~ slim + shld + trks + acpt, data=Highway2)
summary(lm3)
#Model 4: AccidentRate ~ Truck Volume + Access Points
lm4 <- lm(rate ~ trks + acpt, data=Highway2)
summary(lm4)
library(roxygen2)
roxygenize()
roxygenize()
roxygenize()
roxygenize()
roxygenize()
roxygenize()
library(templateICAr)
roxygenize()
library(templateICAr)
roxygenize()
library(templateICAr)
library(templateICAr)
roxygenize()
library(usethis)
use_build_ignore('R/ignore.R')
roxygenize()
library(templateICAr)
roxygenize()
library(templateICAr)
roxygenize()
library(templateICAr)
library(devtools)
install_github('mandymejia/ciftiTools', ref='1.5')
roxygenize()
library(roxygen2)
roxygenize()
library(templateICAr)
roxygenize()
library(templateICAr)
library(roxygen2)
roxygenize()
library(templateICAr)
library(oro.nifti)
vals <- c(0,1,0.9)
!(vals %in% c(0,1))
if(any(!(vals %in% c(0,1)))) stop('Mask must be binary.')
library(roxygen2)
roxygenize()
library(templateICAr)
roxygenize()
roxygenize()
library(templateICAr)
roxygenize()
library(templateICAr)
roxygenize()
setwd('/Volumes/GoogleDrive/My Drive/ALS-BayesianGLM/DiagnosticICAAnalysis/MelodicICA/DiagnosticICA_20200728/FOLD_1')
list.files()
library(oro.nifti)
test_nii <- readNIfTI('melodic_IC.nii.gz')
dim(test_nii@.Data)
new_nii <- test_nii
inds <- c(1:5)
new_nii <- test_nii[,,,inds]
class(new_nii)
class(test_nii)
new_nii <- test_nii
new_nii@.Data <- new_nii@.Data[,,,inds]
class(new_nii)
mask <- readNIfTI('mask.nii.gz')
img_tmp <- mask
tmp <- GICA[,,,1][mask==1]
tmp <- test_nii[,,,1][mask==1]
length(tmp)
table(mask)
img_tmp[mask==1] <- tmp
class(img_tmp)
setwd('/Volumes/GoogleDrive/My Drive/ALS-BayesianGLM/DiagnosticICAAnalysis')
load('estError.RData')
ls()
setwd('/Volumes/GoogleDrive/My Drive/ALS-BayesianGLM/DiagnosticICAAnalysis')
load('estError.RData')
ls()
names(estObj)
setwd('MelodicICA/DiagnosticICA_20200728/FOLD_1/')
list.files()
GICA_fname <- 'melodic_IC.nii.gz'
library(oro.nifti)
GICA <- readNIfTI(GICA_fname, reorient = FALSE)
mask_fname='mask.nii.gz'
dim(estObj$template_mean)
table(mask)
mask2 <- mask <- readNIfTI(mask_fname, reorient = FALSE)
table(mask)
mask_fname='mask2.nii.gz'
mask2 <- mask <- readNIfTI(mask_fname, reorient = FALSE)
table(mask)
names(estObj)
mask2 <- estObj$mask2
table(mask2)
out_fname = 'result_test'
out_fname_mean <- paste0(out_fname, '_mean')
out_fname_var <- paste0(out_fname, '_var')
dim(estObj$template_mean)
inds <- 1:20
GICA@.Data <- GICA@.Data[,,,inds] #remove non-template ICs
template_mean_nifti <- template_var_nifti <- GICA #copy over header information from GICA
img_tmp <- mask2
l=1
img_tmp[mask2==1] <- template_mean[,l]
template_mean = estObj$template_mean
template_var = estObj$template_var
img_tmp[mask2==1] <- template_mean[,l]
template_mean_nifti[,,,l] <- img_tmp
dim(img_tmp)
dim(template_mean_nifti[,,,l])
template_mean_nifti@.Data[,,,l] <- img_tmp
img_tmp[mask2==1] <- template_var[,l]
template_var_nifti@.Data[,,,l] <- img_tmp
writeNIfTI(template_mean_nifti, out_fname_mean)
out_fname_mean
class(template_mean_nifti)
GICA@dim_info
GICA@dim_
GICA@dim_[5]
GICA@dim_[5] <- length(inds)
GICA@dim_
GICA@.Data <- GICA@.Data[,,,inds] #remove non-template ICs
GICA@dim_[5] <- length(inds)
template_mean_nifti <- template_var_nifti <- GICA #copy over header information from GICA
img_tmp <- mask2
for(l in 1:L){
img_tmp[mask2==1] <- template_mean[,l]
template_mean_nifti@.Data[,,,l] <- img_tmp
img_tmp[mask2==1] <- template_var[,l]
template_var_nifti@.Data[,,,l] <- img_tmp
}
L=length(inds)
for(l in 1:L){
img_tmp[mask2==1] <- template_mean[,l]
template_mean_nifti@.Data[,,,l] <- img_tmp
img_tmp[mask2==1] <- template_var[,l]
template_var_nifti@.Data[,,,l] <- img_tmp
}
writeNIfTI(template_mean_nifti, out_fname_mean)
writeNIfTI(template_var_nifti, out_fname_var)
gdrive_dir <- '~/Google Drive File Stream/My Drive'
main_dir <- file.path(gdrive_dir,'FromBox/RESEARCH/DiagnosticICA/data_analysis/')
data_dir <- '/N/dcwan/projects/hcp'
setwd(main_dir)
# id_36 <- demo$Subject[demo$Age=='36+'] #13 subjects
#
# set.seed(237834)
# id_train_22 <- sort(sample(id_22, 200)) #test or retest rs-fMRI session may be missing for some of these subjects
# id_test_22 <- setdiff(id_22, id_train_22)
# set.seed(237834)
# id_train_31 <- sort(sample(id_31, 200))
# id_test_31 <- setdiff(id_31, id_train_31)
#
# save(id_train_22, id_test_22, id_train_31, id_test_31, file='subjects.Rdata')
load(file='subjects.Rdata')
ii='186949'
ii %in% id_test_22
which(id_test_22 ==ii)
length(id_test_22)
library(roxygen2)
roxygenize()
library(roxygen2)
roxygenize()
library(templateICAr)
